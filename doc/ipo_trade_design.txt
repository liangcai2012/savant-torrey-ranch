IPO Trade Analysis Module Design Document

## Functionality:

1. Collect symbols and metadata of newly-listed companies on the north American market from websites like NASDAQ and IPOScoop, and store these information into a relational database.

2. Using tick data downloaded by SAVANT's Fetcher module for past IPOs, process and perform empirical analysis over these data to extract information that will aid in price variation pattern recognition, IPO classifications, and future IPO predictions. Store and maintain aforementioned analysis results in relational models.

3. Plot tick data for visual inspection.

4. Given metadata and market data obtained for a new IPO, perform real-time analysis to help make trading decisions.


## Interface:

This module is not expected to interact with SAVANT and will be used directly from command line.


## Components:

1. Database:

SQLite will be used for development and testing. When the code reaches production quality, we will move to a real RDBMS such as PostgreSQL to handle concurrent access. 

The database built for this module will contain the following tables:

a) Company overview:
    -- Schema: Company_ID(int), Company_name(char), Exchange_ID(char), Headquarter_location(char), Year_founded(int), Industry_ID(char), Outstanding(float), Shares(float), Current_price(float), Date_updated(char)
    -- Source: reuters and nasdaq for already listed companies
    -- Note: this table will be used by SAVANT. It will be updated on a regular basis

b) Historical IPO overview:
    -- Schema: Company_ID(char), IPO_date(char), Underwriter_IDs(char), Offer_price(float), Opening_price(float), 1st_day_closing_price(float), 1st_day_peak_%_change(char), Scoop_rating(int)
    -- Source: iposcoop(archive and last 100 ipos page) for ipos from 2000
    -- Note: this table provides basic IPO info for companies in table a.

c) IPO Analytics:
    -- Schema(temporary): Company_ID(int), 1st_trade_time(char), 1st_day_highest_price(float), 1st_day_highest_price_time(char), 1st_day_lowest_price(float), 1st_day_lowest_price_time(char), 1st_day_volume(float), more TBD
    -- Source: at, yahoo
    -- Note: the schema for this table is not permanent.

d) Exchange:
    -- Schema: Exchange_ID(int), Exchange_name(char), Market(char)

e) Industry:
    -- Schema: Industry_ID(int), Industry_name(char)

f) Underwriter:
    -- Schema: Underwriter_ID(int), Underwriter_name(char)

The following tables maybe implemented in the future:

g) Pre-IPO:
    -- Schema: Company_name(char), Exchange_name(char), Headquarter_location(char), Year_founded(int), Industry(char), IPO_date(char), Underwriter_IDs(char), Revenues(float), Net_income(float), Year_of_report(int), Price_low(float), Price_high(float), Scoop_rating(int)
    -- Source: iposcoop
    -- Note: this table is for temporarily storing company stock information before it goes public on the IPO date. Once the company's stocks are traded on an exchange, relevant data will be transfered over to table a and b, following the schema described above, and the corresponding entry in this table will be removed. An unique internal ID will also be generated in this process.


2. Data Collection:

a) Web scraping will be the primary method of data collection for this module. Information of companies that are already publicly traded will be scraped from web pages on www.nasdaq.com and www.reuters.com. For companies in the process of issuing their IPOs, data will be retrieved from www.iposcoop.com.

Note: Historical IPO tick data wil be collected by fetcher, which is implemented in SAVANT and thus is not of concern here..


3. Data Analysis: 

a) Mining historical data: TBD

b) Predictive analytics of future IPOs: TBD

c) Analysis of ongoing IPOs: TBD


4. Plotting:

The plotting tool should support the following use scenarios: 

a) Given a ticker symbol and a time range(in days, hours, or minutes), provide a plot of price vs. time for the stock of interest since its IPO. 

b) Given a list of ticker symbols and a time range(in days, hours, or minutes), provide a plot of price vs. time for the stocks of interest since their IPOs. Normalize y-axis if the price range exceeds a certain limit(parameterized perhaps).


## Technical Concerns:

1. DBMS selection:

We consider relational database to be the appropriate storage system for the data of this module. Python will be the primary language used to import, manage, and extract data from the database. The Python DBMS implementation will allow both SQLite and PostgreSQL backends, but only the latter should be used after it is deployed to allow concurrent access.

2. Database access in python:

We can either use SQLAlchemy or plain SQL in python. Using plain SQL through sqlite3 or psycopg2 is fast and straightforward. However, it will likely produce many redundant codes while doing similar queries over different tables. It's possible to implement a wrapper over the existing db library to avoid code redundancy, but this is already a built-in feature of SQLAlchemy. Another advantage of SQLAlchemy is that it provides a declarative approach to database that will make our code more robust and flexible against changes to the physical structure of our tables. This could be very benefitial as the IPO Analytics table will be constantly modified. Finally, in the future in case we want to extend this module into a web application, using SQLAlchemy now we would not need to re-integrate an ORM.

